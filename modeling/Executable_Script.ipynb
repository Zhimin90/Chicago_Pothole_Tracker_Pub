{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"/home/zhimin90/CPT/CSVs/\"\n",
    "from sodapy import Socrata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"data.cityofchicago.org\", None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(data.cityofchicago.org,\n",
    "#                  MyAppToken,\n",
    "#                  userame=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")\n",
    "\n",
    "# First 2000 results, returned as JSON from API / converted to Python list of\n",
    "# dictionaries by sodapy.\n",
    "results = client.get(\"wqdh-9gek\",order=\"request_date DESC\", limit=100000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = results_df\n",
    "test_df.columns = pd.Series(test_df.columns).apply(lambda x: x.upper()).values\n",
    "xbound = (-87.9361,-87.5245)\n",
    "ybound = (41.6447,42.023)\n",
    "test_df = test_df[test_df.LATITUDE.notna()].sort_values(['REQUEST_DATE','COMPLETION_DATE'], ascending=[0,0])\n",
    "test_df['REQUEST_DATE'] = pd.to_datetime(test_df['REQUEST_DATE'])\n",
    "test_df['COMPLETION_DATE'] = pd.to_datetime(test_df['COMPLETION_DATE'])\n",
    "test_df['LATITUDE'] = pd.to_numeric(test_df['LATITUDE'])\n",
    "test_df['LONGITUDE'] = pd.to_numeric(test_df['LONGITUDE'])\n",
    "df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_arr = []\n",
    "interval_int = 30 #use 30 days data to predict next 7 days\n",
    "series_range = 7 #days\n",
    "time_interval = timedelta(days=interval_int)\n",
    "date_start = min(df['REQUEST_DATE'])\n",
    "date_end = max(df['REQUEST_DATE'])\n",
    "\n",
    "geo_price_map = df[['REQUEST_DATE', 'COMPLETION_DATE','LATITUDE', 'LONGITUDE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of remaining is: 52640\n"
     ]
    }
   ],
   "source": [
    "filter1a = pd.to_numeric(geo_price_map[\"LONGITUDE\"]) > xbound[0]\n",
    "filter1b = pd.to_numeric(geo_price_map[\"LONGITUDE\"]) < xbound[1]\n",
    "filter1c = pd.to_numeric(geo_price_map[\"LATITUDE\"]) > ybound[0]\n",
    "filter1d = pd.to_numeric(geo_price_map[\"LATITUDE\"]) < ybound[1]\n",
    "print(\"sum of remaining is: \" + str(sum(filter1a&filter1b&filter1c&filter1d)))\n",
    "geo_price_map = geo_price_map[filter1a&filter1b&filter1c&filter1d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-19 14:02:01\n",
      "2020-03-20 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-02-12 14:02:01\n",
      "2020-03-13 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-02-05 14:02:01\n",
      "2020-03-06 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-01-29 14:02:01\n",
      "2020-02-28 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-01-22 14:02:01\n",
      "2020-02-21 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-01-15 14:02:01\n",
      "2020-02-14 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-01-08 14:02:01\n",
      "2020-02-07 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2020-01-01 14:02:01\n",
      "2020-01-31 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-12-25 14:02:01\n",
      "2020-01-24 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-12-18 14:02:01\n",
      "2020-01-17 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-12-11 14:02:01\n",
      "2020-01-10 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-12-04 14:02:01\n",
      "2020-01-03 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-11-27 14:02:01\n",
      "2019-12-27 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-11-20 14:02:01\n",
      "2019-12-20 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-11-13 14:02:01\n",
      "2019-12-13 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-11-06 14:02:01\n",
      "2019-12-06 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-10-30 14:02:01\n",
      "2019-11-29 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-10-23 14:02:01\n",
      "2019-11-22 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-10-16 14:02:01\n",
      "2019-11-15 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-10-09 14:02:01\n",
      "2019-11-08 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-10-02 14:02:01\n",
      "2019-11-01 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-09-25 14:02:01\n",
      "2019-10-25 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-09-18 14:02:01\n",
      "2019-10-18 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-09-11 14:02:01\n",
      "2019-10-11 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-09-04 14:02:01\n",
      "2019-10-04 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-08-28 14:02:01\n",
      "2019-09-27 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-08-21 14:02:01\n",
      "2019-09-20 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-08-14 14:02:01\n",
      "2019-09-13 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-08-07 14:02:01\n",
      "2019-09-06 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-07-31 14:02:01\n",
      "2019-08-30 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-07-24 14:02:01\n",
      "2019-08-23 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-07-17 14:02:01\n",
      "2019-08-16 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-07-10 14:02:01\n",
      "2019-08-09 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-07-03 14:02:01\n",
      "2019-08-02 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-06-26 14:02:01\n",
      "2019-07-26 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-06-19 14:02:01\n",
      "2019-07-19 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-06-12 14:02:01\n",
      "2019-07-12 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-06-05 14:02:01\n",
      "2019-07-05 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-05-29 14:02:01\n",
      "2019-06-28 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-05-22 14:02:01\n",
      "2019-06-21 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-05-15 14:02:01\n",
      "2019-06-14 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-05-08 14:02:01\n",
      "2019-06-07 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-05-01 14:02:01\n",
      "2019-05-31 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-04-24 14:02:01\n",
      "2019-05-24 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-04-17 14:02:01\n",
      "2019-05-17 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-04-10 14:02:01\n",
      "2019-05-10 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-04-03 14:02:01\n",
      "2019-05-03 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-03-27 14:02:01\n",
      "2019-04-26 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-03-20 14:02:01\n",
      "2019-04-19 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-03-13 14:02:01\n",
      "2019-04-12 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-03-06 14:02:01\n",
      "2019-04-05 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-02-27 14:02:01\n",
      "2019-03-29 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-02-20 14:02:01\n",
      "2019-03-22 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-02-13 14:02:01\n",
      "2019-03-15 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-02-06 14:02:01\n",
      "2019-03-08 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-01-30 14:02:01\n",
      "2019-03-01 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-01-23 14:02:01\n",
      "2019-02-22 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-01-16 14:02:01\n",
      "2019-02-15 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-01-09 14:02:01\n",
      "2019-02-08 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2019-01-02 14:02:01\n",
      "2019-02-01 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-12-26 14:02:01\n",
      "2019-01-25 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-12-19 14:02:01\n",
      "2019-01-18 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-12-12 14:02:01\n",
      "2019-01-11 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-12-05 14:02:01\n",
      "2019-01-04 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-11-28 14:02:01\n",
      "2018-12-28 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-11-21 14:02:01\n",
      "2018-12-21 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-11-14 14:02:01\n",
      "2018-12-14 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-11-07 14:02:01\n",
      "2018-12-07 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-10-31 14:02:01\n",
      "2018-11-30 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-10-24 14:02:01\n",
      "2018-11-23 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-10-17 14:02:01\n",
      "2018-11-16 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-10-10 14:02:01\n",
      "2018-11-09 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-10-03 14:02:01\n",
      "2018-11-02 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-09-26 14:02:01\n",
      "2018-10-26 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-09-19 14:02:01\n",
      "2018-10-19 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-09-12 14:02:01\n",
      "2018-10-12 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-09-05 14:02:01\n",
      "2018-10-05 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-08-29 14:02:01\n",
      "2018-09-28 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-08-22 14:02:01\n",
      "2018-09-21 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-08-15 14:02:01\n",
      "2018-09-14 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-08-08 14:02:01\n",
      "2018-09-07 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-08-01 14:02:01\n",
      "2018-08-31 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-07-25 14:02:01\n",
      "2018-08-24 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-07-18 14:02:01\n",
      "2018-08-17 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-07-11 14:02:01\n",
      "2018-08-10 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-07-04 14:02:01\n",
      "2018-08-03 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-06-27 14:02:01\n",
      "2018-07-27 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-06-20 14:02:01\n",
      "2018-07-20 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-06-13 14:02:01\n",
      "2018-07-13 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-06-06 14:02:01\n",
      "2018-07-06 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-05-30 14:02:01\n",
      "2018-06-29 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-05-23 14:02:01\n",
      "2018-06-22 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-05-16 14:02:01\n",
      "2018-06-15 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-05-09 14:02:01\n",
      "2018-06-08 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-05-02 14:02:01\n",
      "2018-06-01 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-04-25 14:02:01\n",
      "2018-05-25 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-04-18 14:02:01\n",
      "2018-05-18 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-04-11 14:02:01\n",
      "2018-05-11 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-04-04 14:02:01\n",
      "2018-05-04 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-03-28 14:02:01\n",
      "2018-04-27 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-03-21 14:02:01\n",
      "2018-04-20 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-03-14 14:02:01\n",
      "2018-04-13 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-03-07 14:02:01\n",
      "2018-04-06 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-28 14:02:01\n",
      "2018-03-30 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-02-21 14:02:01\n",
      "2018-03-23 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-02-14 14:02:01\n",
      "2018-03-16 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n",
      "2018-02-07 14:02:01\n",
      "2018-03-09 14:02:01\n",
      "pothole count: 52640\n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "for int_cur_date in range(0, (date_end - date_start).days - interval_int, int(series_range)):\n",
    "    geo_price_map_filtered = geo_price_map[geo_price_map['LONGITUDE'].notnull()]\n",
    "    \n",
    "    filter2 = geo_price_map_filtered['REQUEST_DATE'] > (date_end - timedelta(days=int_cur_date+interval_int))\n",
    "    filter3 = geo_price_map_filtered['REQUEST_DATE'] <= (date_end -  timedelta(days=int_cur_date))\n",
    "    \n",
    "    print(date_end - timedelta(days=int_cur_date+interval_int))\n",
    "    print(date_end -  timedelta(days=int_cur_date))\n",
    "    \n",
    "    geo_price_map_filtered = geo_price_map_filtered.where(filter2 & filter3)\n",
    "    print(\"pothole count: \" + str(len(geo_price_map_filtered.notnull().index)))\n",
    "    print(\"_\"*20)\n",
    "    map_arr.append(geo_price_map_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_arr.reverse()\n",
    "pothole_count = []\n",
    "for df in map_arr:\n",
    "    pothole_count.append(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as st\n",
    "from scipy.stats import gaussian_kde as gaussian_kde\n",
    "import numpy as np\n",
    "from KDEpy import FFTKDE, NaiveKDE\n",
    "\n",
    "\n",
    "def get_kde( x, y, xmin, xmax, ymin, ymax, xx, yy, positions):\n",
    "\n",
    "    values = np.array([x, y]).T\n",
    "    #values = values.reshape(values.shape[1], values.shape[0])\n",
    "    #print(\"values is: \" + str(values))\n",
    "    #grid, points = get_kernel(values)\n",
    "    points = get_kernel(values, positions)\n",
    "    #kernel.set_bandwidth(bw_method=kernel.factor / 30.)\n",
    "    f = np.reshape(points, xx.shape)\n",
    "    #print(points.shape)\n",
    "    #print(grid)\n",
    "    #return grid, f\n",
    "    return f\n",
    "\n",
    "def get_kernel(data, positions):\n",
    "    #print(data.shape)\n",
    "    #print(data)\n",
    "    estimator = FFTKDE(kernel='gaussian', norm=2, bw=0.001)\n",
    "    #grid, points = estimator.fit(data, weights=None).evaluate(grid_size)\n",
    "    points = estimator.fit(data, weights=None).evaluate(positions)\n",
    "    #grid, points = estimator.fit(data, weights=None).evaluate(grid_size)\n",
    "    #kernel = gaussian_kde(dataset=values, bw_method=\"silverman\" )\n",
    "    #return grid, points\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 1000\n",
    "density_matrix_t_series = []\n",
    "# Define the borders\n",
    "x = [-87.9361,-87.5245]\n",
    "y = [41.6447,42.023]\n",
    "deltaX = (max(x) - min(x))/10\n",
    "deltaY = (max(y) - min(y))/10\n",
    "xmin = min(x) - deltaX\n",
    "xmax = max(x) + deltaX\n",
    "ymin = min(y) - deltaY\n",
    "ymax = max(y) + deltaY\n",
    "\n",
    "xx, yy = np.mgrid[xmin:xmax:(grid_size*1j), ymin:ymax:(grid_size*1j)]\n",
    "positions = np.dstack([xx.ravel(), yy.ravel()])\n",
    "positions = positions.reshape(positions.shape[1], positions.shape[2])\n",
    "grid_matrix = positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@22\n",
      "@26\n",
      "@27\n",
      "@28\n",
      "@29\n",
      "@30\n",
      "@31\n",
      "@32\n",
      "@33\n",
      "@34\n",
      "@35\n",
      "@36\n",
      "@37\n",
      "@38\n",
      "@39\n",
      "@40\n",
      "@41\n",
      "@42\n",
      "@43\n",
      "@44\n",
      "@45\n",
      "@46\n",
      "@47\n",
      "@48\n",
      "@49\n",
      "@50\n",
      "@51\n",
      "@52\n",
      "@53\n",
      "@54\n",
      "@55\n",
      "@56\n",
      "@57\n",
      "@58\n",
      "@59\n",
      "@60\n",
      "@61\n",
      "@62\n",
      "@63\n",
      "@64\n",
      "@65\n",
      "@66\n",
      "@67\n",
      "@68\n",
      "@69\n",
      "@70\n",
      "@71\n",
      "@72\n",
      "@73\n",
      "@74\n",
      "@75\n",
      "@76\n",
      "@77\n",
      "@78\n",
      "@79\n",
      "@80\n",
      "@81\n",
      "@82\n",
      "@83\n",
      "@84\n",
      "@85\n",
      "@86\n",
      "@87\n",
      "@88\n",
      "@89\n",
      "@90\n",
      "@91\n",
      "@92\n",
      "@93\n",
      "@94\n",
      "@95\n",
      "@96\n",
      "@97\n",
      "@98\n",
      "@99\n",
      "@100\n",
      "@101\n",
      "@102\n",
      "@103\n",
      "@104\n",
      "@105\n",
      "@106\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(map_arr):\n",
    "    if df[\"LONGITUDE\"].count() > 400:\n",
    "        #grid, points = get_kde(df[\"LONGITUDE\"].dropna().to_numpy(), df[\"LATITUDE\"].dropna().to_numpy() , xmin, xmax, ymin, ymax, xx, yy, positions)\n",
    "        points = get_kde(df[\"LONGITUDE\"].dropna().to_numpy(), df[\"LATITUDE\"].dropna().to_numpy() , xmin, xmax, ymin, ymax, xx, yy, positions)\n",
    "        density_matrix_t_series.append(points)\n",
    "        print(\"@\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = round(len(density_matrix_t_series)*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "f_in = open(CSV_PATH +'Scalers.pkl', \"rb\")\n",
    "scaler,scaler2 = dill.load(f_in)\n",
    "f_in.close()\n",
    "\n",
    "dm_series_np = np.array(density_matrix_t_series[s:])\n",
    "flattened_matrix_np = np.reshape(dm_series_np, (dm_series_np.shape[0]*dm_series_np.shape[1], dm_series_np.shape[2]))\n",
    "\n",
    "normalized_matrices_test = scaler2.transform(scaler.transform(flattened_matrix_np))\n",
    "x_test = normalized_matrices_test[0:-normalized_matrices_test.shape[1]].copy()\n",
    "y_test = normalized_matrices_test[normalized_matrices_test.shape[1]-1:-1].copy()\n",
    "\n",
    "x_test2 = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "y_test2 = y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(CSV_PATH + 'TensorFlowModel_2020_train_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def predictor(model, data_in, grid, start_frame_date, end_frame_date, time_shift):\n",
    "    xx, yy = grid\n",
    "    offset = yy.shape[0]\n",
    "    print(\"offset = yy.shape[0]\" + str(offset))\n",
    "    xx = xx.ravel()\n",
    "    yy = yy.ravel()\n",
    "    xdelta = abs(xx[1] - xx[1+offset])\n",
    "    ydelta = abs(yy[0] - yy[1+offset])\n",
    "    print(\"xdelta\"+str(xdelta))\n",
    "    print(\"ydelta\"+str(ydelta))\n",
    "    columns = [ 'start_date', 'end_date', 'poly_coordinate', 'density']\n",
    "    \n",
    "    pred = model.predict(data_in)\n",
    "    data = scaler.inverse_transform(scaler2.inverse_transform(pred))\n",
    "    data_reshaped = data.reshape((int(data.shape[0]/data.shape[1]), data.shape[1], data.shape[1]))\n",
    "    print(data_reshaped.shape)\n",
    "    #each cell is a density estimate from KDE that that has been aggregated by number of potholes over time\n",
    "    #This time interval of density cell is input frame time + timeshift the target frame in the model that has shifted forward by\n",
    "    \n",
    "    row_dict = {'start_date' : None, 'end_date' : None, 'poly_coordinate': None, 'density': 0}\n",
    "    #append = pd.DataFrame(columns=columns)\n",
    "    dict_list = []\n",
    "    for t, matrix in enumerate(data_reshaped):\n",
    "        xy_matrix = np.flip(np.rot90(matrix),0)\n",
    "        print(xy_matrix.shape)\n",
    "        row_dict['start_date'] = pd.to_datetime(start_frame_date) + timedelta(days=(time_shift*(t+1)))\n",
    "        row_dict['end_date'] = pd.to_datetime(end_frame_date) + timedelta(days=(time_shift*(t+1)))\n",
    "        \n",
    "        for i, row in enumerate(xy_matrix):\n",
    "            for j, cell in enumerate(row):\n",
    "                pos_index = i + j*xy_matrix.shape[1]\n",
    "                #generate density cell (square) polycoordinate [[cxmin,cymin],[cxmax, cymin],[cxmin, cymax],[cxmax, cymax]]\n",
    "                row_dict['poly_coordinate'] = [[xx[pos_index],yy[pos_index]],[xx[pos_index]+xdelta,yy[pos_index]],[xx[pos_index]+xdelta,yy[pos_index]+ydelta], [xx[pos_index],yy[pos_index]+ydelta]]\n",
    "                row_dict['density'] = cell\n",
    "                dict_list.append(row_dict.copy())\n",
    "\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_time_frame = y_test2[-(y_test2.shape[1]+1):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset = yy.shape[0]1000\n",
      "xdelta0.0004944144144189977\n",
      "ydelta0.0004544144144134066\n",
      "(1, 1000, 1000)\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "start_frame_date = min(map_arr[-1]['REQUEST_DATE'][map_arr[-1]['REQUEST_DATE'].notna()])\n",
    "end_frame_date = max(map_arr[-1]['REQUEST_DATE'][map_arr[-1]['REQUEST_DATE'].notna()])\n",
    "time_shift = 7 #days\n",
    "dataframe = predictor(model,np.reshape(Last_time_frame,(Last_time_frame.shape[0],1,Last_time_frame.shape[1])), (xx, yy), start_frame_date, end_frame_date, time_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-87.97726, 41.60687],\n",
       " [-87.97676558558558, 41.60687],\n",
       " [-87.97676558558558, 41.607324414414414],\n",
       " [-87.97726, 41.607324414414414]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['poly_coordinate'].iloc[0]\n",
    "#dataframe['density'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>poly_coordinate</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-26 14:08:21</td>\n",
       "      <td>2020-03-27 14:02:01</td>\n",
       "      <td>[[-87.97726, 41.60687], [-87.97676558558558, 4...</td>\n",
       "      <td>-1.415854e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-26 14:08:21</td>\n",
       "      <td>2020-03-27 14:02:01</td>\n",
       "      <td>[[-87.97676558558558, 41.60687], [-87.97627117...</td>\n",
       "      <td>-1.415755e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-26 14:08:21</td>\n",
       "      <td>2020-03-27 14:02:01</td>\n",
       "      <td>[[-87.97627117117118, 41.60687], [-87.97577675...</td>\n",
       "      <td>-1.415757e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-26 14:08:21</td>\n",
       "      <td>2020-03-27 14:02:01</td>\n",
       "      <td>[[-87.97577675675676, 41.60687], [-87.97528234...</td>\n",
       "      <td>-1.415717e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-26 14:08:21</td>\n",
       "      <td>2020-03-27 14:02:01</td>\n",
       "      <td>[[-87.97528234234234, 41.60687], [-87.97478792...</td>\n",
       "      <td>-1.415782e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_date            end_date  \\\n",
       "0 2020-02-26 14:08:21 2020-03-27 14:02:01   \n",
       "1 2020-02-26 14:08:21 2020-03-27 14:02:01   \n",
       "2 2020-02-26 14:08:21 2020-03-27 14:02:01   \n",
       "3 2020-02-26 14:08:21 2020-03-27 14:02:01   \n",
       "4 2020-02-26 14:08:21 2020-03-27 14:02:01   \n",
       "\n",
       "                                     poly_coordinate       density  \n",
       "0  [[-87.97726, 41.60687], [-87.97676558558558, 4... -1.415854e-13  \n",
       "1  [[-87.97676558558558, 41.60687], [-87.97627117... -1.415755e-13  \n",
       "2  [[-87.97627117117118, 41.60687], [-87.97577675... -1.415757e-13  \n",
       "3  [[-87.97577675675676, 41.60687], [-87.97528234... -1.415717e-13  \n",
       "4  [[-87.97528234234234, 41.60687], [-87.97478792... -1.415782e-13  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe\n",
    "df[\"int_density\"] = df.density.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for index, row in df.iterrows():\n",
    "    list.append( [row['start_date'],  row['end_date'],Polygon( row['poly_coordinate']), row['density'], row['int_density']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(list, columns =['start_date','end_date', 'geometry', 'density', 'int_density'])\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-87.97726] [41.60687]\n"
     ]
    }
   ],
   "source": [
    "grid_size = 1\n",
    "xgrid = np.arange(xmin, xmax, (xmax-xmin)/grid_size)\n",
    "ygrid = np.arange(ymin, ymax, (ymax-ymin)/grid_size)\n",
    "print(xgrid,ygrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-87.97726 41.60687\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "gdf[\"zone\"] = None\n",
    "for row in xgrid:\n",
    "    for col in ygrid:\n",
    "        print(row,col)\n",
    "        print(c)\n",
    "        current_index = gdf.cx[row:row+(xmax-xmin)/grid_size, col:col+(ymax-ymin)/grid_size].index\n",
    "        gdf.iloc[current_index,5] = c\n",
    "        #print(current_index)\n",
    "        #print(gdf.iloc[current_index,:])\n",
    "        #gdf.cx[row:row+(xmax-xmin)/100, col:col+(ymax-ymin)/100][\"zone\"] = c\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dissolved = gdf.dissolve(by=['int_density','zone'])\n",
    "gdf_dissolved[[\"geometry\",\"density\"]].plot(column='density',figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
